#回归评价指标MSE、RMSE、MAE、R-Squared
##前言
分类问题的评价指标是准确率，那么回归算法的评价指标就是MSE，RMSE，MAE、R-Squared。下面一一介绍
##均方误差（MSE）
MSE （Mean Squared Error）叫做均方误差。看公式


这里的y是测试集上的。

用 真实值-预测值 然后平方之后求和平均。

猛着看一下这个公式是不是觉得眼熟，这不就是线性回归的损失函数嘛！！！ 对，在线性回归的时候我们的目的就是让这个损失函数最小。那么模型做出来了，我们把损失函数丢到测试集上去看看损失值不就好了嘛。简单直观暴力！
##均方根误差（RMSE）
RMSE（Root Mean Squard Error）均方根误差。

这不就是MSE开个根号么。有意义么？其实实质是一样的。只不过用于数据更好的描述。
例如：要做房价预测，每平方是万元（真贵），我们预测结果也是万元。那么差值的平方单位应该是 千万级别的。那我们不太好描述自己做的模型效果。怎么说呢？我们的模型误差是 多少千万？。。。。。。于是干脆就开个根号就好了。我们误差的结果就跟我们数据是一个级别的可，在描述模型的时候就说，我们模型的误差是多少万元。

##MAE(平均绝对误差)


##R Squared
上面的几种衡量标准针对不同的模型会有不同的值。比如说预测房价 那么误差单位就是万元。数子可能是3，4，5之类的。那么预测身高就可能是0.1，0.6之类的。没有什么可读性，到底多少才算好呢？不知道，那要根据模型的应用场景来。
看看分类算法的衡量标准就是正确率，而正确率又在0～1之间，最高百分之百。最低0。很直观，而且不同模型一样的。那么线性回归有没有这样的衡量标准呢？答案是有的。
那就是R Squared也就R方

光看这些东西很懵逼，其中分子是Residual Sum of Squares 分母是 Total Sum of Squares
那就看公式吧

懵逼（X2）
慢慢解释。其实这个很简单。
上面分子就是我们训练出的模型预测的所有误差。
下面分母就是不管什么我们猜的结果就是y的平均数。（瞎猜的误差）
那结果就来了。
如果结果是0，就说明我们的模型跟瞎猜差不多。
如果结果是1。就说明我们模型无错误。
如果结果是0-1之间的数，就是我们模型的好坏程度。
如果结果是负数。说明我们的模型还不如瞎猜。（其实导致这种情况说明我们的数据其实没有啥线性关系）
化简上面的公式
分子分母同时除以m

那么分子就变成了我们的均方误差MSE，下面分母就变成了方差

##代码部分
###MSE
y_preditc=reg.predict(x_test) #reg是训练好的模型
mse_test=np.sum((y_preditc-y_test)**2)/len(y_test) #跟数学公式一样的
###RMSE
rmse_test=mse_test ** 0.5
##MAE
mae_test=np.sum(np.absolute(y_preditc-y_test))/len(y_test)
###R Squared
1- mean_squared_error(y_test,y_preditc)/ np.var(y_test)
###scikit-learn中的各种衡量指标
from sklearn.metrics import mean_squared_error #均方误差
from sklearn.metrics import mean_absolute_error #平方绝对误差
from sklearn.metrics import r2_score#R square
调用
mean_squared_error(y_test,y_predict)
mean_absolute_error(y_test,y_predict)
r2_score(y_test,y_predict)
